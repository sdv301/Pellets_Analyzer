# ml_optimizer.py
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler
from scipy.optimize import minimize
import warnings
import re
from typing import Dict, List, Tuple, Optional
warnings.filterwarnings('ignore')

class PelletPropertyPredictor:
    """
    –ú–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–≤–æ–π—Å—Ç–≤ –ø–µ–ª–ª–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ—Å—Ç–∞–≤–∞
    """
    def __init__(self):
        self.models = {}  # property_name -> trained_model
        self.scalers = {}  # property_name -> scaler
        self.feature_names = []  # –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.is_trained = False
        
    def prepare_features(self, data: pd.DataFrame) -> Tuple[np.ndarray, List[str]]:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ (–∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã) –∏–∑ –¥–∞–Ω–Ω—ã—Ö
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞—Ç—Ä–∏—Ü—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ —Å–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        """
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–∑ –¥–∞–Ω–Ω—ã—Ö
        component_columns = []
        possible_components = [
            '–û–ø–∏–ª–∫–∏', '–°–æ–ª–æ–º–∞', '–ö–∞—Ä—Ç–æ–Ω', '–ü–æ–¥—Å–æ–ª–Ω–µ—á–Ω—ã–π_–∂–º—ã—Ö', 
            '–†–∏—Å–æ–≤–∞—è_—à–µ–ª—É—Ö–∞', '–£–≥–æ–ª—å–Ω—ã–π_—à–ª–∞–º', '–¢–æ—Ä—Ñ', '–ë—É—Ä—ã–π_—É–≥–æ–ª—å', 
            '–°–ú–°', '–ü–ª–∞—Å—Ç–∏–∫', '–î—Ä–µ–≤–µ—Å–Ω–∞—è_–º—É–∫–∞', '–©–µ–ø–∞'
        ]
        
        # –ò—â–µ–º –∫–æ–ª–æ–Ω–∫–∏ —Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏ –≤ –¥–∞–Ω–Ω—ã—Ö
        for comp in possible_components:
            if comp in data.columns:
                component_columns.append(comp)
        
        if not component_columns:
            # –ï—Å–ª–∏ –Ω–µ—Ç –≥–æ—Ç–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫, –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–∑ composition
            component_columns = self._extract_components_from_composition(data)
        
        self.feature_names = component_columns
        print(f"üìã –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {len(component_columns)}")
        print(f"üìã –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: {component_columns}")
        
        # –°–æ–∑–¥–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        X = data[component_columns].fillna(0).values
        return X, component_columns
    
    def _extract_components_from_composition(self, data: pd.DataFrame) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ composition"""
        all_components = set()
        
        for comp_str in data.get('composition', []):
            if pd.notna(comp_str):
                # –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥ - –∏—â–µ–º —Å–ª–æ–≤–∞-–∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
                words = re.findall(r'[–ê-–Ø–∞-—èA-Za-z_]+', str(comp_str))
                for word in words:
                    if len(word) > 2:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞
                        all_components.add(word)
        
        return list(all_components)[:15]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    
    def train(self, data: pd.DataFrame, target_properties: List[str]) -> bool:
        """
        –û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–≤–æ–π—Å—Ç–≤
        """
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
            X, feature_names = self.prepare_features(data)
            self.feature_names = feature_names
            
            if X.shape[1] == 0:
                print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
                return False
            
            trained_count = 0
            
            for target_property in target_properties:
                if target_property not in data.columns:
                    print(f"‚ö†Ô∏è –°–≤–æ–π—Å—Ç–≤–æ {target_property} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –¥–∞–Ω–Ω—ã—Ö")
                    continue
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
                y = data[target_property].values
                valid_mask = ~np.isnan(y)
                
                if np.sum(valid_mask) < 5:
                    print(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {target_property}: {np.sum(valid_mask)} samples")
                    continue
                
                X_clean = X[valid_mask]
                y_clean = y[valid_mask]
                
                # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(X_clean)
                
                # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/test
                X_train, X_test, y_train, y_test = train_test_split(
                    X_scaled, y_clean, test_size=0.2, random_state=42, 
                    shuffle=True
                )
                
                # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
                model = RandomForestRegressor(
                    n_estimators=100,
                    max_depth=10,
                    min_samples_split=5,
                    min_samples_leaf=2,
                    random_state=42,
                    n_jobs=-1
                )
                
                model.fit(X_train, y_train)
                
                # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
                y_pred = model.predict(X_test)
                r2 = r2_score(y_test, y_pred)
                mae = mean_absolute_error(y_test, y_pred)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
                self.models[target_property] = model
                self.scalers[target_property] = scaler
                
                trained_count += 1
                print(f"‚úÖ –ú–æ–¥–µ–ª—å {target_property}: R¬≤={r2:.3f}, MAE={mae:.3f}")
            
            self.is_trained = trained_count > 0
            print(f"üéØ –û–±—É—á–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: {trained_count}")
            return self.is_trained
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
            return False
    
    def predict(self, composition: Dict[str, float], target_property: str) -> Optional[float]:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ —Å–≤–æ–π—Å—Ç–≤–∞ –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —Å–æ—Å—Ç–∞–≤–∞
        """
        if not self.is_trained or target_property not in self.models:
            return None
        
        try:
            # –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            features = np.array([[composition.get(comp, 0.0) for comp in self.feature_names]])
            
            # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º
            scaler = self.scalers[target_property]
            features_scaled = scaler.transform(features)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º
            prediction = self.models[target_property].predict(features_scaled)[0]
            return prediction
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            return None

class CompositionOptimizer:
    """
    AI Agent –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å–æ—Å—Ç–∞–≤–∞ –ø–µ–ª–ª–µ—Ç
    """
    def __init__(self, predictor: PelletPropertyPredictor):
        self.predictor = predictor
        self.available_components = predictor.feature_names if predictor else []
    
    def optimize(self, 
                target_property: str, 
                maximize: bool = True,
                constraints: Optional[Dict] = None,
                max_iterations: int = 1000) -> Dict:
        """
        –ù–∞—Ö–æ–¥–∏—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Å–æ—Å—Ç–∞–≤ –¥–ª—è –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏–∏/–º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ —Ü–µ–ª–µ–≤–æ–≥–æ —Å–≤–æ–π—Å—Ç–≤–∞
        
        Args:
            target_property: –°–≤–æ–π—Å—Ç–≤–æ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            maximize: True - –º–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å, False - –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å
            constraints: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã {'component': (min, max)}
            max_iterations: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        """
        if not self.predictor.is_trained or target_property not in self.predictor.models:
            return {
                'success': False,
                'error': f'–ú–æ–¥–µ–ª—å –¥–ª—è —Å–≤–æ–π—Å—Ç–≤–∞ {target_property} –Ω–µ –æ–±—É—á–µ–Ω–∞'
            }
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        if constraints is None:
            constraints = {}
        
        n_components = len(self.available_components)
        
        def objective_function(x):
            """–¶–µ–ª–µ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
            composition = dict(zip(self.available_components, x))
            prediction = self.predictor.predict(composition, target_property)
            
            if prediction is None:
                return 1e6  # –ë–æ–ª—å—à–∞—è —à—Ç—Ä–∞—Ñ–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
            
            return -prediction if maximize else prediction
        
        def sum_constraint(x):
            """–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ: —Å—É–º–º–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ = 100%"""
            return np.sum(x) - 100
        
        def component_constraints(x):
            """–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã"""
            constraints_list = []
            
            for i, comp in enumerate(self.available_components):
                if comp in constraints:
                    min_val, max_val = constraints[comp]
                    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Å–Ω–∏–∑—É
                    constraints_list.append(x[i] - min_val)
                    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Å–≤–µ—Ä—Ö—É  
                    constraints_list.append(max_val - x[i])
                else:
                    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è 0-100%
                    constraints_list.append(x[i])  # >= 0
                    constraints_list.append(100 - x[i])  # <= 100
            
            return constraints_list
        
        # –ù–∞—á–∞–ª—å–Ω–æ–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ (—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)
        x0 = np.ones(n_components) * (100 / n_components)
        
        # –ì—Ä–∞–Ω–∏—Ü—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
        bounds = [(0, 100) for _ in range(n_components)]
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
        constraints_optim = [
            {'type': 'eq', 'fun': sum_constraint},
            {'type': 'ineq', 'fun': component_constraints}
        ]
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
        try:
            result = minimize(
                objective_function,
                x0,
                method='SLSQP',
                bounds=bounds,
                constraints=constraints_optim,
                options={'maxiter': max_iterations, 'disp': False}
            )
            
            if result.success:
                optimal_composition = dict(zip(self.available_components, result.x))
                optimal_value = -result.fun if maximize else result.fun
                
                # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ —Å–≤–æ–π—Å—Ç–≤–∞ –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–∞–≤–∞
                all_predictions = {}
                for prop in self.predictor.models.keys():
                    all_predictions[prop] = self.predictor.predict(optimal_composition, prop)
                
                return {
                    'success': True,
                    'optimal_composition': optimal_composition,
                    'optimal_value': optimal_value,
                    'target_property': target_property,
                    'all_predictions': all_predictions,
                    'iterations': result.nit,
                    'message': '–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ'
                }
            else:
                return {
                    'success': False,
                    'error': f'–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–µ —Å–æ—à–ª–∞—Å—å: {result.message}',
                    'optimal_composition': dict(zip(self.available_components, result.x))
                }
                
        except Exception as e:
            return {
                'success': False,
                'error': f'–û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {str(e)}'
            }
    
    def find_best_existing(self, data: pd.DataFrame, target_property: str, maximize: bool = True) -> Dict:
        """
        –ù–∞—Ö–æ–¥–∏—Ç –ª—É—á—à–∏–π —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Å–æ—Å—Ç–∞–≤ –∏–∑ –¥–∞–Ω–Ω—ã—Ö
        –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        """
        if target_property not in data.columns:
            return {'success': False, 'error': f'–°–≤–æ–π—Å—Ç–≤–æ {target_property} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –¥–∞–Ω–Ω—ã—Ö'}
        
        valid_data = data.dropna(subset=[target_property])
        if valid_data.empty:
            return {'success': False, 'error': '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞'}
        
        if maximize:
            best_idx = valid_data[target_property].idxmax()
        else:
            best_idx = valid_data[target_property].idxmin()
        
        best_row = valid_data.loc[best_idx]
        best_composition = {}
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–æ—Å—Ç–∞–≤
        for comp in self.available_components:
            if comp in valid_data.columns:
                best_composition[comp] = best_row[comp]
        
        return {
            'success': True,
            'composition': best_composition,
            'value': best_row[target_property],
            'source': 'existing_data',
            'message': f'–õ—É—á—à–∏–π —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Å–æ—Å—Ç–∞–≤ ({"–º–∞–∫—Å–∏–º—É–º" if maximize else "–º–∏–Ω–∏–º—É–º"})'
        }

class PelletMLSystem:
    """
    –ì–ª–∞–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ ML –∞–Ω–∞–ª–∏–∑–∞ –ø–µ–ª–ª–µ—Ç
    """
    def __init__(self, db_path: str = 'pellets_data.db'):
        self.db_path = db_path
        self.predictor = PelletPropertyPredictor()
        self.optimizer = CompositionOptimizer(self.predictor)
        self.training_data = None
    
    def load_training_data(self) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏–∑ –±–∞–∑—ã"""
        try:
            from database import query_db
            data = query_db(self.db_path, "measured_parameters")
            print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(data)} –∑–∞–ø–∏—Å–µ–π")
            self.training_data = data
            return data
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return pd.DataFrame()
    
    def train_models(self, target_properties: List[str] = None) -> bool:
        """–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–≤–æ–π—Å—Ç–≤"""
        if target_properties is None:
            target_properties = ['q', 'density', 'ad', 'kf']
        
        data = self.load_training_data()
        if data.empty:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return False
        
        print(f"üî¨ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Å–≤–æ–π—Å—Ç–≤: {target_properties}")
        success = self.predictor.train(data, target_properties)
        
        if success:
            print("‚úÖ –°–∏—Å—Ç–µ–º–∞ ML –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!")
        else:
            print("‚ùå –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –Ω–µ —É–¥–∞–ª–æ—Å—å")
        
        return success
    
    def optimize_composition(self, target_property: str, **kwargs) -> Dict:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç —Å–æ—Å—Ç–∞–≤ –¥–ª—è —Ü–µ–ª–µ–≤–æ–≥–æ —Å–≤–æ–π—Å—Ç–≤–∞"""
        if not self.predictor.is_trained:
            return {'success': False, 'error': '–ú–æ–¥–µ–ª–∏ –Ω–µ –æ–±—É—á–µ–Ω—ã'}
        
        print(f"üéØ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–∞–≤–∞ –¥–ª—è —Å–≤–æ–π—Å—Ç–≤–∞: {target_property}")
        return self.optimizer.optimize(target_property, **kwargs)
    
    def get_system_status(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã"""
        status = {
            'is_trained': self.predictor.is_trained,
            'trained_models': list(self.predictor.models.keys()),
            'available_components': self.predictor.feature_names,
            'training_data_size': len(self.training_data) if self.training_data is not None else 0
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–µ–π
        model_metrics = {}
        for prop, model in self.predictor.models.items():
            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –º–µ—Ç—Ä–∏–∫
            model_metrics[prop] = {
                'feature_importance': dict(zip(
                    self.predictor.feature_names, 
                    model.feature_importances_
                )) if hasattr(model, 'feature_importances_') else {}
            }
        
        status['model_metrics'] = model_metrics
        return status

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–∏—Å—Ç–µ–º—ã
ml_system = PelletMLSystem()