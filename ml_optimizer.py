# ml_optimizer.py
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler
from scipy.optimize import minimize
import warnings
import re
from typing import Dict, List, Tuple, Optional
warnings.filterwarnings('ignore')


class CompositionParser:
    def __init__(self):
        self.component_patterns = {
            '–û–ø–∏–ª–∫–∏': [r'–æ–ø–∏–ª–∫–∏?', r'–¥—Ä–µ–≤–µ—Å–Ω\w*\s*–æ–ø–∏–ª–∫–∏?'],
            '–°–æ–ª–æ–º–∞': [r'—Å–æ–ª–æ–º[–∞—É—ã]?', r'–ø—à–µ–Ω–∏—á–Ω\w*\s*—Å–æ–ª–æ–º'],
            '–ö–∞—Ä—Ç–æ–Ω': [r'–∫–∞—Ä—Ç–æ–Ω?'],
            '–ü–æ–¥—Å–æ–ª–Ω–µ—á–Ω—ã–π_–∂–º—ã—Ö': [r'–ø–æ–¥—Å–æ–ª–Ω–µ—á–Ω\w*\s*–∂–º—ã—Ö', r'–∂–º—ã—Ö\s*–ø–æ–¥—Å–æ–ª–Ω–µ—á–Ω\w*'],
            '–†–∏—Å–æ–≤–∞—è_—à–µ–ª—É—Ö–∞': [r'—Ä–∏—Å–æ–≤\w*\s*—à–µ–ª—É—Ö', r'—à–µ–ª—É—Ö\w*\s*—Ä–∏—Å–æ–≤\w*'],
            '–£–≥–æ–ª—å–Ω—ã–π_—à–ª–∞–º': [r'—É–≥–æ–ª—å–Ω\w*\s*—à–ª–∞–º', r'—à–ª–∞–º\s*—É–≥–æ–ª—å–Ω\w*'],
            '–¢–æ—Ä—Ñ': [r'—Ç–æ—Ä—Ñ'],
            '–ë—É—Ä—ã–π_—É–≥–æ–ª—å': [r'–±—É—Ä—ã–π\s*—É–≥–æ–ª—å', r'—É–≥–æ–ª—å\s*–±—É—Ä—ã–π'],
            '–°–ú–°': [r'—Å–º—Å', r'cmc', r'—Å\.?–º\.?—Å'],  # –î–æ–±–∞–≤–ª–µ–Ω—ã –ª–∞—Ç–∏–Ω—Å–∫–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
            '–ü–ª–∞—Å—Ç–∏–∫': [r'–ø–ª–∞—Å—Ç–∏–∫'],
            '–î—Ä–µ–≤–µ—Å–Ω–∞—è_–º—É–∫–∞': [r'–¥—Ä–µ–≤–µ—Å–Ω\w*\s*–º—É–∫', r'–º—É–∫\w*\s*–¥—Ä–µ–≤–µ—Å–Ω\w*'],
            '–©–µ–ø–∞': [r'—â–µ–ø']
        }

    def parse_composition(self, composition_text: str) -> Dict[str, float]:
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä —Å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–æ–π"""
        if pd.isna(composition_text) or not composition_text:
            return {}
        
        original_text = str(composition_text)
        text = original_text.lower()
        
        composition_dict = {}
        found_matches = []
        
        # –®–∞–≥ 1: –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –ø—Ä–æ—Ü–µ–Ω—Ç-–∫–æ–º–ø–æ–Ω–µ–Ω—Ç –ø–∞—Ä—ã
        main_pattern = r'(\d+(?:\.\d+)?)%\s*([^%,+]+?)(?=\s*[,+%]|$)'
        matches = re.findall(main_pattern, text)
        
        for percentage_str, comp_text in matches:
            percentage = float(percentage_str)
            comp_text = comp_text.strip()
            
            # –ò—â–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
            matched_component = None
            for comp_name, patterns in self.component_patterns.items():
                for pattern in patterns:
                    if re.search(pattern, comp_text):
                        matched_component = comp_name
                        found_matches.append(f"{comp_name}: {percentage}%")
                        break
                if matched_component:
                    break
            
            if matched_component:
                composition_dict[matched_component] = composition_dict.get(matched_component, 0) + percentage
        
        # –®–∞–≥ 2: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø–æ—Å–ª–µ + (–±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è –ø—Ä–æ—Ü–µ–Ω—Ç–∞)
        if '+' in text and composition_dict:
            plus_components = re.findall(r'\+\s*([^%+,]+)', text)
            
            if plus_components:
                # –ë–µ—Ä–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ –∏ –¥–µ–ª–∏–º –µ–≥–æ
                last_component = list(composition_dict.keys())[-1]
                last_percentage = composition_dict[last_component]
                shared_percentage = last_percentage / (len(plus_components) + 1)
                
                # –ü–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º
                composition_dict[last_component] = shared_percentage
                
                for comp_text in plus_components:
                    comp_text = comp_text.strip()
                    matched_component = None
                    for comp_name, patterns in self.component_patterns.items():
                        for pattern in patterns:
                            if re.search(pattern, comp_text):
                                matched_component = comp_name
                                found_matches.append(f"{comp_name}: +{shared_percentage:.1f}%")
                                break
                        if matched_component:
                            break
                    
                    if matched_component:
                        composition_dict[matched_component] = composition_dict.get(matched_component, 0) + shared_percentage
        
        # –®–∞–≥ 3: –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫ 100%
        total = sum(composition_dict.values())
        if total > 0:
            if abs(total - 100) > 1.0:
                for comp in composition_dict:
                    composition_dict[comp] = (composition_dict[comp] / total) * 100
            composition_dict = {k: round(v, 2) for k, v in composition_dict.items()}
        
        return composition_dict

class PelletPropertyPredictor:
    """
    ML –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–≤–æ–π—Å—Ç–≤ –ø–µ–ª–ª–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ—Å—Ç–∞–≤–∞
    """
    def __init__(self, ml_system=None):
        self.models = {}
        self.scalers = {}
        self.feature_names = []
        self.is_trained = False
        self.training_metrics = {}
        self.parser = CompositionParser()
        self.ml_system = ml_system  # –î–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ linear_predict
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–µ–ª–µ–≤—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö (–Ω–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏)
        self.target_properties_mapping = {
            'war': '–í–ª–∞–∂–Ω–æ—Å—Ç—å –Ω–∞ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫—É—é –º–∞—Å—Å—É',
            'ad': '–ó–æ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ —Å—É—Ö—É—é –º–∞—Å—Å—É', 
            'vd': '–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –ª–µ—Ç—É—á–∏—Ö –Ω–∞ —Å—É—Ö—É—é –º–∞—Å—Å—É',
            'q': '–¢–µ–ø–ª–æ—Ç–∞ —Å–≥–æ—Ä–∞–Ω–∏—è',
            'cd': '–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —É–≥–ª–µ—Ä–æ–¥–∞ –Ω–∞ —Å—É—Ö—É—é –º–∞—Å—Å—É',
            'hd': '–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –≤–æ–¥–æ—Ä–æ–¥–∞ –Ω–∞ —Å—É—Ö—É—é –º–∞—Å—Å—É',
            'nd': '–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –∞–∑–æ—Ç–∞ –Ω–∞ —Å—É—Ö—É—é –º–∞—Å—Å—É',
            'sd': '–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Å–µ—Ä—ã –Ω–∞ —Å—É—Ö—É—é –º–∞—Å—Å—É',
            'od': '–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –∫–∏—Å–ª–æ—Ä–æ–¥–∞ –Ω–∞ —Å—É—Ö—É—é –º–∞—Å—Å—É'
        }
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ —Ü–µ–ª–µ–≤—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        self.main_target_properties = list(self.target_properties_mapping.keys())  # ['war', 'ad', ...]
    
    def prepare_features(self, data: pd.DataFrame) -> Tuple[np.ndarray, List[str], List[int]]:
        """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –±–∞–∑–æ–≤–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–æ–π"""
        if 'composition' not in data.columns:
            print("‚ùå –ö–æ–ª–æ–Ω–∫–∞ 'composition' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return np.array([]), [], []
        
        print(f"üîç –ê–Ω–∞–ª–∏–∑ {len(data)} —Å–æ—Å—Ç–∞–≤–æ–≤...")
        
        all_components = set()
        composition_data = []
        valid_indices = []
        
        for idx, row in data.iterrows():
            composition_dict = self.parser.parse_composition(row['composition'])
            if composition_dict:
                all_components.update(composition_dict.keys())
                composition_data.append(composition_dict)
                valid_indices.append(idx)
        
        component_list = sorted(list(all_components))
        
        if not component_list:
            return np.array([]), [], []
        
        print(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(component_list)} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {component_list}")
        
        # –°–æ–∑–¥–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        X = []
        final_valid_indices = []
        
        for i, comp_dict in enumerate(composition_data):
            row = [comp_dict.get(comp, 0.0) for comp in component_list]
            total = sum(row)
            if total > 10:  # –ú–∏–Ω–∏–º—É–º 10%
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 100%
                row = [(val / total) * 100 for val in row]
                X.append(row)
                final_valid_indices.append(valid_indices[i])
        
        if not X:
            return np.array([]), [], []
        
        X = np.array(X)
        print(f"üìä –§–∏–Ω–∞–ª—å–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞: {X.shape}")
        
        return X, component_list, final_valid_indices
    
    def train(self, data: pd.DataFrame, target_properties: List[str], algorithm: str = 'gradient_boosting') -> bool:
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å—é –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞"""
        X, feature_names, valid_indices = self.prepare_features(data)
        if len(X) == 0:
            return False
        
        self.feature_names = feature_names
        trained_count = 0
        
        print(f"üìä –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è {len(X)} samples, {len(feature_names)} features")
        
        for prop in target_properties:
            y = data[prop].iloc[valid_indices]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –¥–∞–Ω–Ω—ã—Ö
            valid_y = y.dropna()
            if len(valid_y) < 8:
                print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫ {prop}: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö ({len(valid_y)} < 8)")
                continue
            
            print(f"üéØ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è {prop} ({len(valid_y)} samples)")
            
            # –£–¥–∞–ª—è–µ–º NaN
            valid_mask = ~y.isna()
            X_prop = X[valid_mask]
            y_prop = y[valid_mask]
            
            # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–æ–º –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –ø–æ–¥—Ö–æ–¥
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X_prop)
            
            # –ü—Ä–æ—Å—Ç–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
            if algorithm == 'random_forest':
                model = RandomForestRegressor(
                    n_estimators=50,
                    max_depth=5,
                    min_samples_split=5,
                    min_samples_leaf=2,
                    random_state=42
                )
            else:  # gradient_boosting
                model = GradientBoostingRegressor(
                    n_estimators=50,
                    max_depth=3,
                    learning_rate=0.1,
                    random_state=42
                )
            
            # –û–±—É—á–∞–µ–º –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö (–∫–∞–∫ –±—ã–ª–æ —Ä–∞–Ω—å—à–µ)
            model.fit(X_scaled, y_prop)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫
            y_pred = model.predict(X_scaled)
            r2 = r2_score(y_prop, y_pred)
            mae = mean_absolute_error(y_prop, y_pred)
            
            # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏
            cv_scores = cross_val_score(model, X_scaled, y_prop, cv=min(5, len(y_prop)), scoring='r2')
            avg_cv_r2 = np.mean(cv_scores)
            
            self.models[prop] = model
            self.scalers[prop] = scaler
            
            # –í–û–ó–í–†–ê–©–ê–ï–ú –°–¢–ê–†–£–Æ –°–¢–†–£–ö–¢–£–†–£ –î–õ–Ø –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò
            self.training_metrics[prop] = {
                'r2_score': r2,
                'mae': mae,
                'cv_r2': avg_cv_r2,
                # –î–æ–±–∞–≤–ª—è–µ–º feature_importance –≤ –∫–æ—Ä–µ–Ω—å –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                'feature_importance': {}
            }
            
            # Feature importance (–æ—Ç–¥–µ–ª—å–Ω–æ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
            if hasattr(model, 'feature_importances_'):
                feature_importance = model.feature_importances_
                total = sum(feature_importance)
                normalized = feature_importance / total if total != 0 else feature_importance
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –¥–≤—É—Ö –º–µ—Å—Ç–∞—Ö –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                self.training_metrics[prop]['feature_importance'] = dict(zip(feature_names, normalized))
            
            print(f"   ‚úÖ {prop}: R¬≤={r2:.3f}, MAE={mae:.3f}, CV R¬≤={avg_cv_r2:.3f}")
            trained_count += 1
        
        self.is_trained = trained_count > 0
        
        if self.is_trained:
            print(f"‚úÖ –û–±—É—á–µ–Ω–æ {trained_count} –º–æ–¥–µ–ª–µ–π")
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏")
        
        return self.is_trained
    
    def predict(self, composition: Dict[str, float], target_property: str) -> Optional[float]:
        """–ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Å–≤–æ–π—Å—Ç–≤–æ: ML –µ—Å–ª–∏ –æ–±—É—á–µ–Ω–æ, –∏–Ω–∞—á–µ –ª–∏–Ω–µ–π–Ω–æ–µ –∏–∑ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        if target_property not in self.models:
            if self.ml_system:
                return self.ml_system.linear_predict(composition, target_property)
            return None
        
        X = self.prepare_composition_for_prediction(composition)
        scaler = self.scalers[target_property]
        X_scaled = scaler.transform([X])
        model = self.models[target_property]
        return model.predict(X_scaled)[0]
    
    def prepare_composition_for_prediction(self, composition: Dict[str, float]) -> np.ndarray:
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —Å–æ—Å—Ç–∞–≤ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"""
        total = sum(composition.values())
        if total != 100:
            composition = {k: (v / total) * 100 for k, v in composition.items()}
        
        X = [composition.get(feature, 0.0) for feature in self.feature_names]
        return np.array(X)
    
    def get_feature_importance(self, target_property: str) -> Dict[str, float]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Å–≤–æ–π—Å—Ç–≤–∞"""
        if target_property not in self.training_metrics:
            return {}
        return self.training_metrics[target_property].get('feature_importance', {})

class MLCompositionOptimizer:
    """–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Å–æ—Å—Ç–∞–≤–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ ML –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
    
    def __init__(self, predictor):
        self.predictor = predictor
        self.optimization_history = []
    
    def optimize_composition(self, target_property: str, maximize: bool = True, constraints: Dict[str, Tuple[float, float]] = None) -> Dict:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç —Å–æ—Å—Ç–∞–≤ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π"""
        if target_property not in self.predictor.models:
            return {'success': False, 'error': f'–ú–æ–¥–µ–ª—å –¥–ª—è {target_property} –Ω–µ –æ–±—É—á–µ–Ω–∞'}
        
        feature_names = self.predictor.feature_names
        n_features = len(feature_names)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
        if constraints:
            min_total = 0.0
            max_total = 0.0
            
            for comp, (min_val, max_val) in constraints.items():
                if comp in feature_names:
                    min_total += min_val
                    max_total += max_val
            
            print(f"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π: min_total={min_total:.1f}%, max_total={max_total:.1f}%")
            
            # –ï—Å–ª–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å—É–º–º–∞ > 100% - –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º—ã
            if min_total > 100.0:
                return {
                    'success': False, 
                    'error': f'–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º—ã: –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å—É–º–º–∞ {min_total:.1f}% > 100%'
                }
            
            # –ï—Å–ª–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å—É–º–º–∞ < 100% - —Ç–æ–∂–µ –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º—ã
            if max_total < 100.0:
                return {
                    'success': False, 
                    'error': f'–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º—ã: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å—É–º–º–∞ {max_total:.1f}% < 100%'
                }
        
        # –ù–∞—á–∞–ª—å–Ω—ã–π —Å–æ—Å—Ç–∞–≤ - —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        initial_composition = np.full(n_features, 1.0 / n_features)
        
        def objective(composition):
            try:
                comp_dict = dict(zip(feature_names, composition * 100))
                pred = self.predictor.predict(comp_dict, target_property)
                if pred is None:
                    return 1e6 if maximize else -1e6
                return -pred if maximize else pred
            except:
                return 1e6 if maximize else -1e6
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ: —Å—É–º–º–∞ = 100%
        def sum_constraint(composition):
            return sum(composition) - 1.0
        
        cons = [{'type': 'eq', 'fun': sum_constraint}]
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        bounds = [(0.0, 1.0) for _ in range(n_features)]
        if constraints:
            for comp, (min_val, max_val) in constraints.items():
                if comp in feature_names:
                    idx = feature_names.index(comp)
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç—ã –≤ –¥–æ–ª–∏
                    bounds[idx] = (max(min_val / 100.0, 0.0), min(max_val / 100.0, 1.0))
        
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        methods = ['SLSQP', 'trust-constr']
        best_result = None
        best_value = -np.inf if maximize else np.inf
        
        for method in methods:
            try:
                result = minimize(
                    objective, 
                    initial_composition, 
                    method=method, 
                    bounds=bounds, 
                    constraints=cons, 
                    options={'maxiter': 500, 'disp': False}
                )
                
                if result.success:
                    current_value = -result.fun if maximize else result.fun
                    if (maximize and current_value > best_value) or (not maximize and current_value < best_value):
                        best_result = result
                        best_value = current_value
            except Exception as e:
                print(f"‚ö†Ô∏è –ú–µ—Ç–æ–¥ {method} –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
                continue
        
        # –ï—Å–ª–∏ –Ω–∏ –æ–¥–∏–Ω –º–µ—Ç–æ–¥ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –ø—Ä–æ–±—É–µ–º –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
        if best_result is None:
            print("üîÑ –ü—Ä–æ–±—É—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π...")
            try:
                result = minimize(
                    objective, 
                    initial_composition, 
                    method='SLSQP', 
                    constraints=cons, 
                    options={'maxiter': 500, 'disp': False}
                )
                if result.success:
                    best_result = result
            except:
                pass
        
        if best_result is None:
            return {
                'success': False, 
                'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ä–µ—à–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –æ—Å–ª–∞–±–∏—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è.'
            }
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        optimal_composition = dict(zip(feature_names, best_result.x * 100))
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –Ω—É–ª–µ–≤—ã–µ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        optimal_composition = {k: round(v, 2) for k, v in optimal_composition.items() if v > 0.1}
        total = sum(optimal_composition.values())
        
        if total > 0 and abs(total - 100) > 0.1:
            optimal_composition = {k: round((v / total) * 100, 2) for k, v in optimal_composition.items()}
        
        optimal_value = -best_result.fun if maximize else best_result.fun
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–±–ª—é–¥–µ–Ω–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
        if constraints:
            violations = []
            for comp, (min_val, max_val) in constraints.items():
                if comp in optimal_composition:
                    value = optimal_composition[comp]
                    if value < min_val - 0.1 or value > max_val + 0.1:
                        violations.append(f"{comp}: {value:.1f}% (—Ç—Ä–µ–±—É–µ—Ç—Å—è {min_val:.1f}-{max_val:.1f}%)")
            
            if violations:
                return {
                    'success': False,
                    'error': f'–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±–ª—é—Å—Ç–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è: {", ".join(violations)}'
                }
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è
        display_name = self.predictor.target_properties_mapping.get(target_property, target_property)
        direction = "–º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏–∏" if maximize else "–º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏"
        comp_text = ", ".join([f"{k}: {v:.1f}%" for k, v in optimal_composition.items()])
        
        message = (f"–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Å–æ—Å—Ç–∞–≤ –¥–ª—è {direction} {display_name}: {comp_text}. "
                f"–û–∂–∏–¥–∞–µ–º–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {optimal_value:.2f}.")
        
        print(f"‚úÖ {message}")
        
        self.optimization_history.append({
            'target_property': target_property,
            'optimal_composition': optimal_composition,
            'optimal_value': optimal_value,
            'message': message
        })
        
        return {
            'success': True,
            'optimal_composition': optimal_composition,
            'optimal_value': optimal_value,
            'message': message
        }

    def validate_constraints(self, constraints: Dict[str, Tuple[float, float]], feature_names: List[str]) -> Tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π"""
        if not constraints:
            return True, ""
        
        min_total = 0.0
        max_total = 0.0
        invalid_components = []
        
        for comp, (min_val, max_val) in constraints.items():
            if comp not in feature_names:
                invalid_components.append(comp)
                continue
                
            if min_val < 0 or max_val > 100 or min_val > max_val:
                return False, f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –¥–ª—è {comp}: {min_val}-{max_val}%"
                
            min_total += min_val
            max_total += max_val
        
        if invalid_components:
            return False, f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: {', '.join(invalid_components)}"
        
        if min_total > 100.0:
            return False, f"–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å—É–º–º–∞ {min_total:.1f}% > 100%"
            
        if max_total < 100.0:
            return False, f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å—É–º–º–∞ {max_total:.1f}% < 100%"
        
        return True, ""

class PelletMLSystem:
    """
    –ì–ª–∞–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ ML –∞–Ω–∞–ª–∏–∑–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–µ–ª–ª–µ—Ç
    """
    def __init__(self, db_path: str = 'pellets_data.db'):
        self.db_path = db_path
        self.predictor = PelletPropertyPredictor(self)
        self.ml_optimizer = MLCompositionOptimizer(self.predictor)
        self.training_data = self.load_training_data()
        self.components = self.load_components()
    
    def load_components(self) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–≤–æ–π—Å—Ç–≤–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –∏–∑ –ë–î"""
        try:
            from database import query_db
            components = query_db(self.db_path, "components")
            if components.empty:
                print("‚ö†Ô∏è –¢–∞–±–ª–∏—Ü–∞ components –ø—É—Å—Ç–∞")
            else:
                print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {len(components)}")
            return components
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {e}")
            return pd.DataFrame()
    
    def linear_predict(self, composition: Dict[str, float], target_property: str) -> Optional[float]:
        """–õ–∏–Ω–µ–π–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–≤–æ–π—Å—Ç–≤–∞ –∫–∞–∫ –≤–∑–≤–µ—à–µ–Ω–Ω–æ–π —Å—É–º–º—ã —Å–≤–æ–π—Å—Ç–≤ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        if self.components.empty:
            return None
        value = 0.0
        total_weight = 0.0
        for comp, percent in composition.items():
            if comp in self.components['component'].values:
                row = self.components[self.components['component'] == comp]
                if target_property in row.columns and not pd.isna(row[target_property].iloc[0]):
                    value += (percent / 100.0) * row[target_property].iloc[0]
                    total_weight += percent
        if total_weight > 0:
            return value * (100.0 / total_weight)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –µ—Å–ª–∏ total !=100
        return None
    
    def load_training_data(self) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î"""
        try:
            from database import query_db
            training_data = query_db(self.db_path, "measured_parameters")
            if training_data.empty:
                print("‚ö†Ô∏è –¢–∞–±–ª–∏—Ü–∞ measured_parameters –ø—É—Å—Ç–∞")
            else:
                print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {len(training_data)} –∑–∞–ø–∏—Å–µ–π")
            return training_data
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
            return pd.DataFrame()
    
    def train_models(self, target_properties: List[str] = None, algorithm: str = 'random_forest') -> Dict:
        """–û–±—É—á–∞–µ—Ç ML –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–≤–æ–π—Å—Ç–≤"""
        if self.training_data.empty:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML –æ–±—É—á–µ–Ω–∏—è")
            return {'success': False, 'error': '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è'}
        
        if target_properties is None:
            target_properties = self.predictor.main_target_properties
        
        success = self.predictor.train(self.training_data, target_properties, algorithm)
        
        if success:
            print("‚úÖ ML —Å–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!")
            print("ü§ñ ML Agent –º–æ–∂–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –Ω–æ–≤—ã–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ —Å–æ—Å—Ç–∞–≤—ã")
            status = self.get_ml_system_status()
            return {
                'success': True,
                'message': 'ML —Å–∏—Å—Ç–µ–º–∞ —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞!',
                'status': status,
                'trained_count': len(status['trained_models']),
                'metrics': {prop: status['model_metrics'][prop] for prop in status['trained_models']}
            }
        else:
            print("‚ùå –û–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–µ–π –Ω–µ —É–¥–∞–ª–æ—Å—å")
            return {'success': False, 'error': '–û–±—É—á–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å'}
    
    def optimize_composition(self, target_property: str, maximize: bool = True, constraints: Dict[str, Tuple[float, float]] = None) -> Dict:
        return self.ml_optimizer.optimize_composition(target_property, maximize, constraints)
    
    def get_ml_system_status(self) -> Dict:
        status = {
            'is_trained': self.predictor.is_trained,
            'trained_models': list(self.predictor.models.keys()),
            'available_components': self.predictor.feature_names,
            'training_data_size': len(self.training_data) if not self.training_data.empty else 0,
            'ml_optimizations_count': len(self.ml_optimizer.optimization_history)
        }
        
        model_metrics = {}
        for prop in self.predictor.models.keys():
            # –°–û–í–ú–ï–°–¢–ò–ú–ê–Ø –°–¢–†–£–ö–¢–£–†–ê –î–ê–ù–ù–´–•
            model_metrics[prop] = {
                'feature_importance': self.predictor.training_metrics.get(prop, {}).get('feature_importance', {}),
                'training_metrics': {
                    'r2_score': self.predictor.training_metrics.get(prop, {}).get('r2_score', 0),
                    'mae': self.predictor.training_metrics.get(prop, {}).get('mae', 0),
                    'cv_r2': self.predictor.training_metrics.get(prop, {}).get('cv_r2', 0)
                },
                'display_name': self.predictor.target_properties_mapping.get(prop, prop)
            }
        
        status['model_metrics'] = model_metrics
        status['target_properties_mapping'] = self.predictor.target_properties_mapping
        
        return status

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä ML —Å–∏—Å—Ç–µ–º—ã
ml_system = PelletMLSystem()

def get_ml_system():
    return ml_system