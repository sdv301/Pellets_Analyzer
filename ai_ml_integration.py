# ai_ml_integration.py
import pandas as pd
import numpy as np
import json
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime

logger = logging.getLogger(__name__)

class AIMLAnalyzer:
    def __init__(self, db_path='pellets_data.db'):
        self.db_path = db_path
        self.analysis_history = []
    
    def get_data_summary(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–≤–æ–¥–∫—É –ø–æ –¥–∞–Ω–Ω—ã–º"""
        try:
            from database import query_db
            
            measured_data = query_db(self.db_path, "measured_parameters")
            components_data = query_db(self.db_path, "components")
            
            # –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö
            total_samples = len(measured_data)
            total_components = len(components_data)
            
            # –ê–Ω–∞–ª–∏–∑ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö
            if not measured_data.empty:
                numeric_cols = measured_data.select_dtypes(include=[np.number]).columns
                available_props = [col for col in numeric_cols if col != 'id']
                completeness = measured_data[numeric_cols].notna().mean().mean() if len(numeric_cols) > 0 else 0
            else:
                available_props = []
                completeness = 0
            
            return {
                'total_samples': total_samples,
                'total_components': total_components,
                'available_properties': available_props,
                'data_completeness': round(completeness * 100, 1),
                'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M'),
                'status': 'active' if total_samples > 0 else 'no_data'
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–≤–æ–¥–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return {
                'total_samples': 0,
                'total_components': 0,
                'available_properties': [],
                'data_completeness': 0,
                'status': 'error',
                'error': str(e)
            }
    
    def get_ml_models_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç—É—Å ML –º–æ–¥–µ–ª–µ–π"""
        try:
            from database import get_active_ml_models, get_ml_optimizations
            
            active_models = get_active_ml_models(self.db_path)
            optimizations = get_ml_optimizations(self.db_path, limit=5)
            
            trained_models = []
            if not active_models.empty:
                trained_models = active_models['target_property'].tolist()
            
            # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π
            model_performance = {}
            for _, model in active_models.iterrows():
                prop = model['target_property']
                model_performance[prop] = {
                    'r2_score': round(model.get('r2_score', 0), 3),
                    'status': 'excellent' if model.get('r2_score', 0) > 0.8 else 
                             'good' if model.get('r2_score', 0) > 0.6 else 'needs_improvement'
                }
            
            return {
                'is_trained': len(trained_models) > 0,
                'trained_models': trained_models,
                'models_count': len(trained_models),
                'model_performance': model_performance,
                'recent_optimizations': len(optimizations),
                'last_training': active_models['timestamp'].max() if not active_models.empty else 'Never'
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ ML: {e}")
            return {
                'is_trained': False,
                'trained_models': [],
                'models_count': 0,
                'model_performance': {},
                'status': 'error',
                'error': str(e)
            }
    
    def analyze_with_ai(self, user_query: str, analysis_type: str = "comprehensive") -> Dict[str, Any]:
        """–£–º–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–º–∏ –æ—Ç–≤–µ—Ç–∞–º–∏"""
        try:
            data_summary = self.get_data_summary()
            ml_status = self.get_ml_models_status()
            
            # –ê–Ω–∞–ª–∏–∑ —Ç–∏–ø–∞ –∑–∞–ø—Ä–æ—Å–∞
            query_type = self._classify_query(user_query)
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
            analysis_result = self._generate_contextual_response(user_query, query_type, data_summary, ml_status)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
            self.analysis_history.append({
                'timestamp': datetime.now().isoformat(),
                'query': user_query,
                'type': query_type,
                'response': analysis_result
            })
            
            return analysis_result
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return {
                'analysis': f"‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {str(e)}",
                'recommendations': "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö",
                'success': False
            }
    
    def _classify_query(self, query: str) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        query_lower = query.lower()
        
        if any(word in query_lower for word in ['–æ–ø—Ç–∏–º', '–ª—É—á—à', '–º–∞–∫—Å', '–º–∏–Ω', '—É–ª—É—á—à']):
            return 'optimization'
        elif any(word in query_lower for word in ['—Ç—Ä–µ–Ω–¥', '–∑–∞–≤–∏—Å', '–∫–æ—Ä—Ä–µ–ª', '—Å–≤—è–∑']):
            return 'trends'
        elif any(word in query_lower for word in ['–ø—Ä–µ–¥—Å–∫–∞–∑', '–ø—Ä–æ–≥–Ω–æ–∑', '—Ä–∞—Å—Å—á–∏—Ç']):
            return 'prediction'
        elif any(word in query_lower for word in ['–∞–Ω–∞–ª–∏–∑', '–ø—Ä–æ–∞–Ω–∞–ª–∏–∑', '–∏–∑—É—á']):
            return 'analysis'
        elif any(word in query_lower for word in ['—Å–æ—Å—Ç–∞–≤', '–∫–æ–º–ø–æ–Ω–µ–Ω—Ç', '–∏–Ω–≥—Ä–µ–¥']):
            return 'composition'
        else:
            return 'general'
    
    def _generate_contextual_response(self, query: str, query_type: str, data_summary: Dict, ml_status: Dict) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ –∑–∞–ø—Ä–æ—Å–∞"""
        
        base_info = self._get_base_analysis_info(data_summary, ml_status)
        
        if query_type == 'optimization':
            return self._generate_optimization_response(query, base_info)
        elif query_type == 'trends':
            return self._generate_trends_response(query, base_info)
        elif query_type == 'prediction':
            return self._generate_prediction_response(query, base_info)
        elif query_type == 'composition':
            return self._generate_composition_response(query, base_info)
        else:
            return self._generate_general_response(query, base_info)
    
    def _get_base_analysis_info(self, data_summary: Dict, ml_status: Dict) -> Dict:
        """–ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
        return {
            'samples_count': data_summary.get('total_samples', 0),
            'components_count': data_summary.get('total_components', 0),
            'properties_count': len(data_summary.get('available_properties', [])),
            'data_status': data_summary.get('status', 'unknown'),
            'ml_trained': ml_status.get('is_trained', False),
            'ml_models_count': ml_status.get('models_count', 0),
            'data_completeness': data_summary.get('data_completeness', 0)
        }
    
    def _generate_optimization_response(self, query: str, base_info: Dict) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
        
        if base_info['ml_trained']:
            analysis = f"""
            **üéØ –ê–Ω–∞–ª–∏–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞:** "{query}"
            
            **–¢–µ–∫—É—â–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã:**
            ‚úÖ –û–±—É—á–µ–Ω–æ {base_info['ml_models_count']} ML –º–æ–¥–µ–ª–µ–π
            ‚úÖ –î–æ—Å—Ç—É–ø–Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–∞–≤–æ–≤
            ‚úÖ –ë–∞–∑–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç {base_info['samples_count']} –æ–±—Ä–∞–∑—Ü–æ–≤
            
            **–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –¥–µ–π—Å—Ç–≤–∏—è:**
            1. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ —Ä–∞–∑–¥–µ–ª **ML –ê–Ω–∞–ª–∏–∑**
            2. –í—ã–±–µ—Ä–∏—Ç–µ —Ü–µ–ª–µ–≤–æ–µ —Å–≤–æ–π—Å—Ç–≤–æ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            3. –ó–∞–¥–∞–π—Ç–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º (–ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏)
            4. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é
            
            **–î–æ—Å—Ç—É–ø–Ω—ã–µ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å–≤–æ–π—Å—Ç–≤–∞:**
            - –¢–µ–ø–ª–æ—Ç–∞ —Å–≥–æ—Ä–∞–Ω–∏—è (q)
            - –ü—Ä–æ—á–Ω–æ—Å—Ç—å (kf) 
            - –ó–æ–ª—å–Ω–æ—Å—Ç—å (ad)
            - –ò –¥—Ä—É–≥–∏–µ –∏–∑–º–µ—Ä—è–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            """
        else:
            analysis = f"""
            **üéØ –ê–Ω–∞–ª–∏–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞:** "{query}"
            
            **–¢–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å:**
            ‚ö†Ô∏è ML –º–æ–¥–µ–ª–∏ –Ω–µ –æ–±—É—á–µ–Ω—ã
            üìä –î–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {base_info['samples_count']} –æ–±—Ä–∞–∑—Ü–æ–≤
            
            **–î–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ:**
            1. **–û–±—É—á–∏—Ç—å ML –º–æ–¥–µ–ª–∏** –≤ —Ä–∞–∑–¥–µ–ª–µ ML –∞–Ω–∞–ª–∏–∑–∞
            2. –£–±–µ–¥–∏—Ç—å—Å—è –≤ –Ω–∞–ª–∏—á–∏–∏ –¥–∞–Ω–Ω—ã—Ö –æ —Å–æ—Å—Ç–∞–≤–∞—Ö
            3. –í—ã–±—Ä–∞—Ç—å —Ü–µ–ª–µ–≤—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            
            **–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:**
            - –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ —Ä–∞–∑–¥–µ–ª **ML –ê–Ω–∞–ª–∏–∑**
            - –ù–∞–∂–º–∏—Ç–µ "–û–±—É—á–∏—Ç—å —Å–∏—Å—Ç–µ–º—É ML"
            - –ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é
            """
        
        return {
            'analysis': analysis,
            'recommendations': "–î–ª—è —Ç–æ—á–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ–±—É—á–∏—Ç—å ML –º–æ–¥–µ–ª–∏ –Ω–∞ –∏–º–µ—é—â–∏—Ö—Å—è –¥–∞–Ω–Ω—ã—Ö",
            'actions': ['train_ml', 'optimize'] if not base_info['ml_trained'] else ['optimize'],
            'success': True
        }
    
    def _generate_trends_response(self, query: str, base_info: Dict) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤"""
        
        if base_info['samples_count'] > 10:
            analysis = f"""
            **üìà –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π:** "{query}"
            
            **–î–æ—Å—Ç—É–ø–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:**
            ‚úÖ {base_info['samples_count']} –æ–±—Ä–∞–∑—Ü–æ–≤
            ‚úÖ {base_info['properties_count']} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            ‚úÖ –ó–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö: {base_info['data_completeness']}%
            
            **–ú–µ—Ç–æ–¥—ã –∞–Ω–∞–ª–∏–∑–∞:**
            1. **–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑** - –≤—ã—è–≤–ª–µ–Ω–∏–µ –≤–∑–∞–∏–º–æ—Å–≤—è–∑–µ–π –º–µ–∂–¥—É –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            2. **–¢—Ä–µ–Ω–¥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑** - –ø–æ–∏—Å–∫ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–µ–π –≤ –¥–∞–Ω–Ω—ã—Ö
            3. **–ö–ª–∞—Å—Ç–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑** - –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Å—Ö–æ–∂–∏—Ö —Å–æ—Å—Ç–∞–≤–æ–≤
            
            **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**
            - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–∞–∑–¥–µ–ª **–°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤** –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
            - –ü—Ä–∏–º–µ–Ω–∏—Ç–µ **–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—É—é —Ç–∞–±–ª–∏—Ü—É** –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            - –î–ª—è ML –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤ –æ–±—É—á–∏—Ç–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –º–æ–¥–µ–ª–∏
            """
        else:
            analysis = f"""
            **üìà –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤:** "{query}"
            
            **–¢–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å:**
            ‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤
            üìä –î–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ {base_info['samples_count']} –æ–±—Ä–∞–∑—Ü–æ–≤
            
            **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**
            1. **–î–æ–±–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö** –≤ —Å–∏—Å—Ç–µ–º—É
            2. –£–±–µ–¥–∏—Ç–µ—Å—å –≤ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–∏ —Å–æ—Å—Ç–∞–≤–æ–≤
            3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–ª–Ω–æ—Ç—É –∏–∑–º–µ—Ä—è–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            """
        
        return {
            'analysis': analysis,
            'recommendations': "–î–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–≤–µ–ª–∏—á–∏—Ç—å –æ–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö",
            'actions': ['add_data', 'create_graphs'],
            'success': True
        }
    
    def _generate_prediction_response(self, query: str, base_info: Dict) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
        
        if base_info['ml_trained']:
            analysis = f"""
            **üîÆ –ü—Ä–æ–≥–Ω–æ–∑–Ω—ã–π –∞–Ω–∞–ª–∏–∑:** "{query}"
            
            **–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã:**
            ‚úÖ –û–±—É—á–µ–Ω–æ {base_info['ml_models_count']} ML –º–æ–¥–µ–ª–µ–π
            ‚úÖ –î–æ—Å—Ç—É–ø–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–≤–æ–π—Å—Ç–≤ –ø–æ —Å–æ—Å—Ç–∞–≤—É
            ‚úÖ –¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π: R¬≤ > 0.7 –¥–ª—è –∫–ª—é—á–µ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            
            **–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**
            1. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ **ML –ê–Ω–∞–ª–∏–∑**
            2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            3. –í–≤–µ–¥–∏—Ç–µ —Å–æ—Å—Ç–∞–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            4. –ü–æ–ª—É—á–∏—Ç–µ –ø—Ä–æ–≥–Ω–æ–∑ —Å–≤–æ–π—Å—Ç–≤
            
            **–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:**
            "–ü—Ä–µ–¥—Å–∫–∞–∂–∏ —Ç–µ–ø–ª–æ—Ç—É —Å–≥–æ—Ä–∞–Ω–∏—è –¥–ª—è —Å–æ—Å—Ç–∞–≤–∞: 60% –æ–ø–∏–ª–∫–∏, 30% —Å–æ–ª–æ–º–∞, 10% –ª–∏–≥–Ω–∏–Ω"
            """
        else:
            analysis = f"""
            **üîÆ –ü—Ä–æ–≥–Ω–æ–∑–Ω—ã–π –∞–Ω–∞–ª–∏–∑:** "{query}"
            
            **–¢–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å:**
            ‚ö†Ô∏è ML –º–æ–¥–µ–ª–∏ –Ω–µ –æ–±—É—á–µ–Ω—ã –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
            üìä –î–æ—Å—Ç—É–ø–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {base_info['samples_count']} –æ–±—Ä–∞–∑—Ü–æ–≤
            
            **–î–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è:**
            1. **–û–±—É—á–∏—Ç–µ ML –º–æ–¥–µ–ª–∏** –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–º —Ä–∞–∑–¥–µ–ª–µ
            2. –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            3. –í—ã–±–µ—Ä–∏—Ç–µ —Å–≤–æ–π—Å—Ç–≤–∞ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            
            **–ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –≤—ã —Å–º–æ–∂–µ—Ç–µ:**
            - –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —Å–≤–æ–π—Å—Ç–≤–∞ –ø–æ –Ω–æ–≤—ã–º —Å–æ—Å—Ç–∞–≤–∞–º
            - –û—Ü–µ–Ω–∏–≤–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –ø–µ–ª–ª–µ—Ç –¥–æ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞
            - –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–æ—Å—Ç–∞–≤—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
            """
        
        return {
            'analysis': analysis,
            'recommendations': "–ü—Ä–æ–≥–Ω–æ–∑–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–µ–π",
            'actions': ['train_ml', 'predict'],
            'success': True
        }
    
    def _generate_composition_response(self, query: str, base_info: Dict) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –æ —Å–æ—Å—Ç–∞–≤–∞—Ö"""
        
        analysis = f"""
        **üß™ –ê–Ω–∞–ª–∏–∑ —Å–æ—Å—Ç–∞–≤–æ–≤:** "{query}"
        
        **–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö:**
        üìä –û–±—Ä–∞–∑—Ü–æ–≤ –≤ –±–∞–∑–µ: {base_info['samples_count']}
        üî¨ –ö–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {base_info['components_count']}
        üìà –ó–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç—å: {base_info['data_completeness']}%
        
        **–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:**
        1. **–ü–æ–∏—Å–∫ —Å–æ—Å—Ç–∞–≤–æ–≤** - —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º
        2. **–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–∞–≤–æ–≤** - –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–∏–π
        3. **ML –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è** - –ø–æ–∏—Å–∫ –ª—É—á—à–∏—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π
        
        **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**
        - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ **—Ç–∞–±–ª–∏—Ü—ã** –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –≤—Å–µ—Ö —Å–æ—Å—Ç–∞–≤–æ–≤
        - –ü—Ä–∏–º–µ–Ω—è–π—Ç–µ **–ø–æ–∏—Å–∫** –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö
        - –°—Ä–∞–≤–Ω–∏–≤–∞–π—Ç–µ —Å–æ—Å—Ç–∞–≤—ã –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–º —Ä–∞–∑–¥–µ–ª–µ
        """
        
        return {
            'analysis': analysis,
            'recommendations': "–î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Å–æ—Å—Ç–∞–≤–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–∞–±–ª–∏—Ü—ã –∏ –ø–æ–∏—Å–∫",
            'actions': ['view_tables', 'search', 'compare'],
            'success': True
        }
    
    def _generate_general_response(self, query: str, base_info: Dict) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—â–µ–≥–æ –æ—Ç–≤–µ—Ç–∞"""
        
        analysis = f"""
        **ü§ñ –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑:** "{query}"
        
        **–û–±–∑–æ—Ä —Å–∏—Å—Ç–µ–º—ã:**
        üìä –î–∞–Ω–Ω—ã–µ: {base_info['samples_count']} –æ–±—Ä–∞–∑—Ü–æ–≤, {base_info['properties_count']} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        ü§ñ ML –º–æ–¥–µ–ª–∏: {base_info['ml_models_count']} –æ–±—É—á–µ–Ω–Ω—ã—Ö {'‚úÖ' if base_info['ml_trained'] else '‚ùå'}
        üìà –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö: {base_info['data_completeness']}% –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç–∏
        
        **–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:**
        ‚Ä¢ **–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö** - –ø–æ–∏—Å–∫ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–µ–π –∏ —Ç—Ä–µ–Ω–¥–æ–≤
        ‚Ä¢ **ML –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è** - –ø–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö —Å–æ—Å—Ç–∞–≤–æ–≤
        ‚Ä¢ **–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ** - –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–≤–æ–π—Å—Ç–≤
        ‚Ä¢ **–°—Ä–∞–≤–Ω–µ–Ω–∏–µ** - –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å–æ—Å—Ç–∞–≤–æ–≤
        
        **–ö–∞–∫ –ø–æ–ª—É—á–∏—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –ø–æ–ª—å–∑—É:**
        1. –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –Ω–∞–ª–∏—á–∏–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–≥–æ –æ–±—ä–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö
        2. –û–±—É—á–∏—Ç–µ ML –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–æ—á–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        
        **–ü—Ä–∏–º–µ—Ä—ã —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:**
        ‚Ä¢ "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Ç–µ–ø–ª–æ—Ç—ã —Å–≥–æ—Ä–∞–Ω–∏—è –æ—Ç —Å–æ—Å—Ç–∞–≤–∞"
        ‚Ä¢ "–ù–∞–π–¥–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Å–æ—Å—Ç–∞–≤ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ—á–Ω–æ—Å—Ç–∏"
        ‚Ä¢ "–ö–∞–∫–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ª—É—á—à–µ –≤—Å–µ–≥–æ –≤–ª–∏—è—é—Ç –Ω–∞ —ç–∫–æ–ª–æ–≥–∏—á–Ω–æ—Å—Ç—å?"
        """
        
        return {
            'analysis': analysis,
            'recommendations': "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ—á–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤",
            'actions': ['analyze', 'train_ml', 'optimize'],
            'success': True
        }
    
    def get_analysis_history(self, limit: int = 10) -> List[Dict]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –∞–Ω–∞–ª–∏–∑–æ–≤"""
        return self.analysis_history[-limit:] if self.analysis_history else []
    
    def get_system_recommendations(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é —Å–∏—Å—Ç–µ–º—ã"""
        data_summary = self.get_data_summary()
        ml_status = self.get_ml_models_status()
        
        recommendations = []
        
        if data_summary.get('total_samples', 0) < 20:
            recommendations.append({
                'type': 'data',
                'priority': 'high',
                'message': '–î–æ–±–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è >20 –æ–±—Ä–∞–∑—Ü–æ–≤)',
                'action': 'add_data'
            })
        
        if not ml_status.get('is_trained', False):
            recommendations.append({
                'type': 'ml',
                'priority': 'high', 
                'message': '–û–±—É—á–∏—Ç–µ ML –º–æ–¥–µ–ª–∏ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏',
                'action': 'train_ml'
            })
        
        if data_summary.get('data_completeness', 0) < 80:
            recommendations.append({
                'type': 'quality',
                'priority': 'medium',
                'message': f'–£–ª—É—á—à–∏—Ç–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö (—Å–µ–π—á–∞—Å {data_summary.get("data_completeness", 0)}%)',
                'action': 'improve_data'
            })
        
        return {
            'recommendations': recommendations,
            'total_count': len(recommendations),
            'high_priority_count': len([r for r in recommendations if r['priority'] == 'high'])
        }

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
ai_ml_analyzer = AIMLAnalyzer()